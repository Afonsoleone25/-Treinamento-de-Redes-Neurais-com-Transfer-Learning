# ü¶ü Projeto de Transfer Learning para Detec√ß√£o de Mal√°ria - Bootcamp DIO

## üìå Descri√ß√£o do Projeto
Projeto de **Deep Learning** que aplica **Transfer Learning** para classificar imagens de c√©lulas sangu√≠neas como **Parasitadas** ou **N√£o Infectadas** pela mal√°ria. Este trabalho √© desenvolvido como parte do bootcamp da Digital Innovation One.

## üéØ Objetivo
Implementar um modelo de classifica√ß√£o bin√°ria utilizando redes neurais pr√©-treinadas para auxiliar no diagn√≥stico da mal√°ria a partir de imagens de esfrega√ßos de sangue, documentando todo o processo t√©cnico.

## üèóÔ∏è Arquitetura do Projeto
- **Framework**: TensorFlow / Keras
- **Modelo Base**: MobileNetV2 (ou outro como ResNet50, escolha justificada)
- **Dataset**: **TensorFlow Malaria Dataset** (https://www.tensorflow.org/datasets/catalog/malaria)
- **Ambiente**: Google Colab (recomendado para uso gratuito de GPU)
- **Classes**: `0` (Parasitada) e `1` (N√£o Infectada)

## üìä Dataset
- **Origem**: TensorFlow Datasets (`tfds.load('malaria')`)
- **Descri√ß√£o**: Cont√©m 27.558 imagens de c√©lulas com **ocorr√™ncia igual** (balanceada) de c√©lulas parasitadas e n√£o infectadas.
- **Divis√£o Oficial**: Apenas uma divis√£o `'train'` com todas as 27.558 imagens.
- **Estrutura**: Cada exemplo √© um dicion√°rio com:
  - `'image'`: Imagem RGB de dimens√µes vari√°veis (`(None, None, 3)`, tipo `uint8`).
  - `'label'`: Classe (0 ou 1, tipo `int64`).
- **Tarefa Supervisionada**: Chave `('image', 'label')`.

## üöÄ Implementa√ß√£o Passo a Passo

### 1. Configura√ß√£o do Ambiente no Google Colab
```python
# Instala√ß√£o do TensorFlow Datasets (pode ser necess√°rio no Colab)
!pip install tensorflow-datasets

# Importa√ß√µes principais
import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
import os

# Verifica a vers√£o do TF e se a GPU est√° dispon√≠vel
print("TensorFlow vers√£o:", tf.__version__)
print("GPU dispon√≠vel:", tf.config.list_physical_devices('GPU'))
2. Carregamento e Explora√ß√£o do Dataset
python
# Carregar o dataset Malaria
(ds_train), ds_info = tfds.load('malaria',
                                 split='train',
                                 shuffle_files=True,
                                 as_supervised=True, # Retorna (imagem, r√≥tulo)
                                 with_info=True) # Inclui metadados

# Explorar informa√ß√µes
print(f"N√∫mero total de exemplos: {ds_info.splits['train'].num_examples}")
print(f"Classes: {ds_info.features['label'].names}") # ['parasitized', 'uninfected']

# Visualizar algumas amostras
fig = tfds.show_examples(ds_train.take(9), ds_info)
3. Pr√©-processamento e Divis√£o dos Dados
Como o dataset tem apenas uma divis√£o, voc√™ deve criar manualmente as divis√µes de treino, valida√ß√£o e teste.

python
# Definir propor√ß√µes (exemplo: 70% treino, 15% valida√ß√£o, 15% teste)
TOTAL_EXEMPLOS = ds_info.splits['train'].num_examples
TAMANHO_TREINO = int(0.7 * TOTAL_EXEMPLOS)
TAMANHO_VAL = int(0.15 * TOTAL_EXEMPLOS)
TAMANHO_TESTE = TOTAL_EXEMPLOS - TAMANHO_TREINO - TAMANHO_VAL

# Embaralhar e dividir o dataset
ds = ds_train.shuffle(buffer_size=10000)
ds_treino = ds.take(TAMANHO_TREINO)
ds_restante = ds.skip(TAMANHO_TREINO)
ds_val = ds_restante.take(TAMANHO_VAL)
ds_teste = ds_restante.skip(TAMANHO_VAL)

print(f"Treino: {tf.data.experimental.cardinality(ds_treino).numpy()}")
print(f"Valida√ß√£o: {tf.data.experimental.cardinality(ds_val).numpy()}")
print(f"Teste: {tf.data.experimental.cardinality(ds_teste).numpy()}")

# Fun√ß√£o de pr√©-processamento
def preparar_imagem(image, label, tamanho_alvo=(224, 224)):
    # Redimensionar para o tamanho esperado pelo modelo base
    image = tf.image.resize(image, tamanho_alvo)
    # Normalizar pixels para o intervalo [0, 1] ou [-1, 1] (depende do modelo)
    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)
    return image, label

# Aplicar pr√©-processamento e otimizar o pipeline
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE

ds_treino = (ds_treino
             .map(preparar_imagem, num_parallel_calls=AUTOTUNE)
             .batch(BATCH_SIZE)
             .prefetch(AUTOTUNE))
ds_val = (ds_val
          .map(preparar_imagem, num_parallel_calls=AUTOTUNE)
          .batch(BATCH_SIZE)
          .prefetch(AUTOTUNE))
ds_teste = (ds_teste
            .map(preparar_imagem, num_parallel_calls=AUTOTUNE)
            .batch(BATCH_SIZE)
            .prefetch(AUTOTUNE))
4. Constru√ß√£o do Modelo com Transfer Learning
python
def criar_modelo_transfer_learning():
    # 1. Carregar o modelo base (pr√©-treinado no ImageNet, sem o topo)
    base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),
                                                   include_top=False,
                                                   weights='imagenet')
    # Congelar os pesos do modelo base
    base_model.trainable = False

    # 2. Construir o novo topo do modelo
    inputs = tf.keras.Input(shape=(224, 224, 3))
    # Aplicar o modelo base
    x = base_model(inputs, training=False)
    # Camadas personalizadas
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    x = tf.keras.layers.Dropout(0.2)(x)
    # Camada de sa√≠da para classifica√ß√£o bin√°ria
    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)

    # 3. Criar o modelo completo
    model = tf.keras.Model(inputs, outputs)

    # 4. Compilar o modelo
    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

modelo = criar_modelo_transfer_learning()
modelo.summary() # Visualizar a arquitetura
5. Treinamento do Modelo
python
# Callbacks para melhor controle
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)
checkpoint = tf.keras.callbacks.ModelCheckpoint('melhor_modelo_malaria.keras',
                                                monitor='val_accuracy',
                                                save_best_only=True)

# Treinar
historico = modelo.fit(ds_treino,
                       validation_data=ds_val,
                       epochs=10,
                       callbacks=[early_stopping, checkpoint])
6. Avalia√ß√£o e Resultados
python
# Avaliar no conjunto de teste
resultado_teste = modelo.evaluate(ds_teste)
print(f"Acur√°cia no Teste: {resultado_teste[1]*100:.2f}%")
print(f"Loss no Teste: {resultado_teste[0]:.4f}")

# Gerar matriz de confus√£o (necess√°rio importar sklearn.metrics)
from sklearn.metrics import confusion_matrix, classification_report
import itertools

# Coletar todas as previs√µes e r√≥tulos verdadeiros do conjunto de teste
y_pred = []
y_true = []
for images, labels in ds_teste.unbatch().take(-1):
    pred = modelo.predict(tf.expand_dims(images, axis=0), verbose=0)
    y_pred.append(tf.where(pred > 0.5, 1, 0).numpy()[0][0])
    y_true.append(labels.numpy())

print(classification_report(y_true, y_pred, target_names=['Parasitada', 'N√£o Infectada']))

# Plotar gr√°ficos de Loss e Acur√°cia
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(historico.history['loss'], label='Loss Treino')
plt.plot(historico.history['val_loss'], label='Loss Valida√ß√£o')
plt.title('Loss por √âpoca')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(historico.history['accuracy'], label='Acur√°cia Treino')
plt.plot(historico.history['val_accuracy'], label='Acur√°cia Valida√ß√£o')
plt.title('Acur√°cia por √âpoca')
plt.legend()
plt.tight_layout()
plt.savefig('images/training_history.png')
plt.show()
üìù Aprendizados e Destaques do Projeto
Carregamento de Datasets Oficiais: Aprendi a usar tensorflow-datasets para acessar conjuntos de dados curados.

Divis√£o Manual de Dados: Pratiquei a cria√ß√£o de splits de treino/valida√ß√£o/teste a partir de um √∫nico conjunto.

Pipeline Eficiente com tf.data: Otimizei o carregamento e pr√©-processamento com map, batch e prefetch.

Transfer Learning para Sa√∫de: Apliquei um modelo pr√©-treinado em um problema m√©dico real (classifica√ß√£o de c√©lulas).

Avalia√ß√£o Completa: Gerei m√©tricas detalhadas (matriz de confus√£o, relat√≥rio de classifica√ß√£o) al√©m da simples acur√°cia.

üîÆ Poss√≠veis Melhorias
Fine-Tuning: Descongelar as √∫ltimas camadas do base_model e realizar um segundo treinamento com uma taxa de aprendizado menor.

Experimentar Outras Arquiteturas: Testar EfficientNet ou ResNet50 como modelo base.

Data Augmentation Mais Agressivo: Adicionar rota√ß√£o, zoom e invers√£o de cores para melhor generaliza√ß√£o.

Explicabilidade do Modelo: Usar t√©cnicas como Grad-CAM para visualizar quais regi√µes da c√©lula o modelo est√° "olhando" para tomar a decis√£o.

Deploy Simples: Salvar o modelo e criar uma interface web b√°sica com Streamlit ou Flask para fazer previs√µes em novas imagens.

üìå Conclus√£o
Este projeto demonstrou com sucesso a aplica√ß√£o de Transfer Learning para um problema de classifica√ß√£o de imagens m√©dicas. O uso do TensorFlow Datasets simplificou o acesso aos dados, e a arquitetura modular permitiu experimentar diferentes abordagens. Os resultados servem como uma prova de conceito valiosa para o uso de IA no aux√≠lio ao diagn√≥stico de doen√ßas como a mal√°ria.

text

### üéØ **Pr√≥ximos Passos para Voc√™**

1.  **Crie o Reposit√≥rio no GitHub** com a estrutura de pastas sugerida.
2.  **Copie o c√≥digo acima** para um novo notebook no Google Colab (`transfer_learning_malaria.ipynb`).
3.  **Execute c√©lula por c√©lula**, documentando quaisquer ajustes ou observa√ß√µes que fizer.
4.  **Gere os gr√°ficos e resultados** e salve as imagens mais relevantes na pasta `/images`.
5.  **Suba tudo para o GitHub** e finalize o `README.md` com seus resultados reais (substitua os placeholders pelas suas m√©tricas).

Boa sorte com o projeto! Se tiver d√∫vidas espec√≠ficas durante a implementa√ß√£o, √© s√≥ perguntar.
